{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec_elmo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "WORD2VEC and ELMO\n"
      ],
      "metadata": {
        "id": "CRzAa1viUGfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->Install flair and restarting runtime"
      ],
      "metadata": {
        "id": "-mDpdXTPagzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install allennlp==0.9.0\n",
        "!pip install --user flair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXvhuAm9aerH",
        "outputId": "77c055a2-8bf2-4dc0-c4f2-4322353a5ff2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: allennlp==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (4.64.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (2022.1)\n",
            "Requirement already satisfied: parsimonious>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.9.0)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (2.1.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.6.4)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (21.12.0)\n",
            "Requirement already satisfied: flaky in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.7.0)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: overrides in /root/.local/lib/python3.7/site-packages (from allennlp==0.9.0) (3.1.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.18 in /root/.local/lib/python3.7/site-packages (from allennlp==0.9.0) (2.27.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.22.1)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.21.6)\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.4.2)\n",
            "Requirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.2.5)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (6.1.1)\n",
            "Requirement already satisfied: pytorch-pretrained-bert>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.6.2)\n",
            "Requirement already satisfied: flask-cors>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.0.10)\n",
            "Requirement already satisfied: spacy<2.2,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.0.2)\n",
            "Requirement already satisfied: numpydoc>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.2.1)\n",
            "Collecting conllu==1.3.1\n",
            "  Using cached conllu-1.3.1-py2.py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: pytorch-transformers==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.1.0)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (2.5)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.5.3)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.3.4)\n",
            "Requirement already satisfied: responses>=0.7 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.20.0)\n",
            "Requirement already satisfied: jsonnet>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.18.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.1.0->allennlp==0.9.0) (2022.4.24)\n",
            "Requirement already satisfied: sentencepiece in /root/.local/lib/python3.7/site-packages (from pytorch-transformers==1.1.0->allennlp==0.9.0) (0.1.95)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.9.0) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.9.0) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.9.0) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.9.0) (2.11.3)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors>=3.0.7->allennlp==0.9.0) (1.15.0)\n",
            "Requirement already satisfied: greenlet<2.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.9.0) (1.1.2)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.9.0) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.9.0) (57.4.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.9.0) (5.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.0.2->allennlp==0.9.0) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.9.0) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.9.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.9.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.9.0) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.3->allennlp==0.9.0) (4.2.0)\n",
            "Requirement already satisfied: sphinx>=1.8 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=0.8.0->allennlp==0.9.0) (1.8.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.9.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.9.0) (1.25.11)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.9.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.9.0) (2.10)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (0.9.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (0.9.6)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (0.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (1.0.6)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (7.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (2.0.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp==0.9.0) (21.3)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp==0.9.0) (2.9.1)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp==0.9.0) (1.2.4)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp==0.9.0) (2.6.1)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp==0.9.0) (1.3.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp==0.9.0) (0.7.12)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp==0.9.0) (0.17.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp==0.9.0) (2.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.2->allennlp==0.9.0) (3.17.3)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp==0.9.0) (0.5.2)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp==0.9.0) (1.0.0)\n",
            "Requirement already satisfied: botocore<1.26.0,>=1.25.1 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp==0.9.0) (1.25.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp==0.9.0) (0.2.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp==0.9.0) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata in /root/.local/lib/python3.7/site-packages (from jsonpickle->allennlp==0.9.0) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle->allennlp==0.9.0) (3.8.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /root/.local/lib/python3.7/site-packages (from pytest->allennlp==0.9.0) (8.8.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0) (1.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0) (21.4.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0) (0.7.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp==0.9.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp==0.9.0) (3.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.8->numpydoc>=0.8.0->allennlp==0.9.0) (1.1.5)\n",
            "Installing collected packages: conllu\n",
            "  Attempting uninstall: conllu\n",
            "    Found existing installation: conllu 4.4.1\n",
            "    Uninstalling conllu-4.4.1:\n",
            "      Successfully uninstalled conllu-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flair 0.11.1 requires conllu>=4.0, but you have conllu 1.3.1 which is incompatible.\u001b[0m\n",
            "Successfully installed conllu-1.3.1\n",
            "Requirement already satisfied: flair in /root/.local/lib/python3.7/site-packages (0.11.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2022.4.24)\n",
            "Requirement already satisfied: wikipedia-api in /root/.local/lib/python3.7/site-packages (from flair) (0.5.4)\n",
            "Collecting conllu>=4.0\n",
            "  Using cached conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: langdetect in /root/.local/lib/python3.7/site-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.11.0+cu113)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: more-itertools~=8.8.0 in /root/.local/lib/python3.7/site-packages (from flair) (8.8.0)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /root/.local/lib/python3.7/site-packages (from flair) (0.2.7)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.64.0)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /root/.local/lib/python3.7/site-packages (from flair) (0.1.95)\n",
            "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /root/.local/lib/python3.7/site-packages (from flair) (4.6.5)\n",
            "Requirement already satisfied: pptree in /root/.local/lib/python3.7/site-packages (from flair) (3.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from flair) (6.1.1)\n",
            "Requirement already satisfied: huggingface-hub in /root/.local/lib/python3.7/site-packages (from flair) (0.5.1)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /root/.local/lib/python3.7/site-packages (from flair) (2.0.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /root/.local/lib/python3.7/site-packages (from flair) (1.2.13)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /root/.local/lib/python3.7/site-packages (from flair) (0.3.3)\n",
            "Requirement already satisfied: mpld3==0.3 in /root/.local/lib/python3.7/site-packages (from flair) (0.3)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /root/.local/lib/python3.7/site-packages (from flair) (1.5.11)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: gdown==3.12.2 in /root/.local/lib/python3.7/site-packages (from flair) (3.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: janome in /root/.local/lib/python3.7/site-packages (from flair) (0.4.2)\n",
            "Requirement already satisfied: transformers>=4.0.0 in /root/.local/lib/python3.7/site-packages (from flair) (4.18.0)\n",
            "Requirement already satisfied: requests[socks] in /root/.local/lib/python3.7/site-packages (from gdown==3.12.2->flair) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.14.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (5.2.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (0.16.0)\n",
            "Requirement already satisfied: py4j in /root/.local/lib/python3.7/site-packages (from hyperopt>=0.2.7->flair) (0.10.9.5)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
            "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /root/.local/lib/python3.7/site-packages (from konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n",
            "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /root/.local/lib/python3.7/site-packages (from konoha<5.0.0,>=4.0.0->flair) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.8.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (1.25.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /root/.local/lib/python3.7/site-packages (from transformers>=4.0.0->flair) (0.12.1)\n",
            "Requirement already satisfied: sacremoses in /root/.local/lib/python3.7/site-packages (from transformers>=4.0.0->flair) (0.0.49)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /root/.local/lib/python3.7/site-packages (from transformers>=4.0.0->flair) (6.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Installing collected packages: conllu\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "allennlp 0.9.0 requires conllu==1.3.1, but you have conllu 4.4.1 which is incompatible.\u001b[0m\n",
            "Successfully installed conllu-4.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1)Mounting Gdrive"
      ],
      "metadata": {
        "id": "VPBRkm78sj0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwBN_dWVsiPI",
        "outputId": "b150c386-2f1c-4686-e220-fa85a0fffb50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)Loading Dataset"
      ],
      "metadata": {
        "id": "Si-OPjTRnM3t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BIth6otgeF44"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('drive/MyDrive/Dataset/quora-question-pairs.zip','r') as ZipObj:\n",
        "  ZipObj.extractall('drive/MyDrive/Dataset')"
      ],
      "metadata": {
        "id": "IcCfihCxcFbQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('drive/MyDrive/Dataset/sample_submission.csv.zip','r') as ZipObj:\n",
        "  ZipObj.extractall('drive/MyDrive/Dataset/Train_Test')\n",
        "\n",
        "with ZipFile('drive/MyDrive/Dataset/train.csv.zip','r') as ZipObj:\n",
        "  ZipObj.extractall('drive/MyDrive/Dataset/Train_Test')\n",
        "\n",
        "with ZipFile('drive/MyDrive/Dataset/test.csv.zip','r') as ZipObj:\n",
        "  ZipObj.extractall('drive/MyDrive/Dataset/Train_Test')"
      ],
      "metadata": {
        "id": "lZSJHFwUo0_w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "aTzWFtCdp54M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv('drive/MyDrive/Dataset/Train_Test/train.csv')\n",
        "test=pd.read_csv('drive/MyDrive/Dataset/Train_Test/test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcWHMizBqTpf",
        "outputId": "a820371c-8eed-4c1f-ca13-c12d8fd431f2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape,test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gauw_-5qhGZ",
        "outputId": "2dca2174-3aa9-48ec-c4b4-a181700f5389"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404290, 6), (3563475, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "aSrlv9Jxqjqz",
        "outputId": "fda89065-404f-4c4a-ea40-f1612dd9d0b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2  What is the step by step guide to invest in sh...   \n",
              "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2   2     5     6  How can I increase the speed of my internet co...   \n",
              "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
              "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
              "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
              "6   6    13    14                                Should I buy tiago?   \n",
              "7   7    15    16                     How can I be a good geologist?   \n",
              "8   8    17    18                    When do you use シ instead of し?   \n",
              "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What is the step by step guide to invest in sh...             0  \n",
              "1  What would happen if the Indian government sto...             0  \n",
              "2  How can Internet speed be increased by hacking...             0  \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4            Which fish would survive in salt water?             0  \n",
              "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
              "6  What keeps childern active and far from phone ...             0  \n",
              "7          What should I do to be a great geologist?             1  \n",
              "8              When do you use \"&\" instead of \"and\"?             0  \n",
              "9  How do I hack Motorola DCX3400 for free internet?             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-413f05ce-b90b-4ce5-a3d0-f0f05e6711af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>When do you use シ instead of し?</td>\n",
              "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-413f05ce-b90b-4ce5-a3d0-f0f05e6711af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-413f05ce-b90b-4ce5-a3d0-f0f05e6711af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-413f05ce-b90b-4ce5-a3d0-f0f05e6711af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZhMIwBS3rdpd",
        "outputId": "3ca1f685-9c9f-4875-ca47-7ca96ae28996"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  test_id                                          question1  \\\n",
              "0       0  How does the Surface Pro himself 4 compare wit...   \n",
              "1       1  Should I have a hair transplant at age 24? How...   \n",
              "2       2  What but is the best way to send money from Ch...   \n",
              "3       3                        Which food not emulsifiers?   \n",
              "4       4                   How \"aberystwyth\" start reading?   \n",
              "\n",
              "                                           question2  \n",
              "0  Why did Microsoft choose core m3 and not core ...  \n",
              "1        How much cost does hair transplant require?  \n",
              "2                      What you send money to China?  \n",
              "3                                  What foods fibre?  \n",
              "4                     How their can I start reading?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cf048f1-530c-4781-8462-1b1c1e952658\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
              "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Should I have a hair transplant at age 24? How...</td>\n",
              "      <td>How much cost does hair transplant require?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>What but is the best way to send money from Ch...</td>\n",
              "      <td>What you send money to China?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Which food not emulsifiers?</td>\n",
              "      <td>What foods fibre?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>How \"aberystwyth\" start reading?</td>\n",
              "      <td>How their can I start reading?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cf048f1-530c-4781-8462-1b1c1e952658')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1cf048f1-530c-4781-8462-1b1c1e952658 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1cf048f1-530c-4781-8462-1b1c1e952658');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=train[0:1000]\n",
        "test=test[0:1000]\n",
        "train.shape,test.shape"
      ],
      "metadata": {
        "id": "dYwDEfGmOG0q",
        "outputId": "af26c2ad-26ed-43cb-800a-7bc303e41ed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 6), (1000, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Loading Frequencies"
      ],
      "metadata": {
        "id": "XESzUXFbrwlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def load_tsv(f):\n",
        "    frequencies = {}\n",
        "    with open(f) as tsv:\n",
        "        tsv_reader = csv.reader(tsv, delimiter=\"\\t\")\n",
        "        for row in tsv_reader:\n",
        "            frequencies[row[0]] = int(row[1])\n",
        "\n",
        "    return frequencies\n",
        "\n",
        "\n",
        "def load_frequencies(path):\n",
        "    return load_tsv(path)\n",
        "\n",
        "\n",
        "def load_doc_frequencies(path):\n",
        "    doc_frequencies = load_tsv(path)\n",
        "    doc_frequencies[\"NUM_DOCS\"] = 1288431\n",
        "    return doc_frequencies"
      ],
      "metadata": {
        "id": "ni1HXaEuJqp3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequency = load_frequencies(\"drive/MyDrive/Code_Frequencies_Embeddings/frequencies.tsv\")\n",
        "doc_frequency = load_doc_frequencies(\"drive/MyDrive/Code_Frequencies_Embeddings/doc_frequencies.tsv\")"
      ],
      "metadata": {
        "id": "8aUbZ1suI76R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Loading Embeddings"
      ],
      "metadata": {
        "id": "0b2WzNG_vcKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "def load_word2vec(path):\n",
        "    word2vec = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)\n",
        "    return word2vec"
      ],
      "metadata": {
        "id": "g020fGvtJwmY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyunpack\n",
        "!pip install patool\n",
        "from pyunpack import Archive\n",
        "Archive('drive/MyDrive/Code_Frequencies_Embeddings/GoogleNews-vectors-negative300.bin.gz').extractall('drive/MyDrive/Code_Frequencies_Embeddings')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G2l4kTuvyFn",
        "outputId": "d72480a9-8679-4515-8d91-fa1ce38a0235"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyunpack in /usr/local/lib/python3.7/dist-packages (0.2.2)\n",
            "Requirement already satisfied: easyprocess in /usr/local/lib/python3.7/dist-packages (from pyunpack) (1.1)\n",
            "Requirement already satisfied: entrypoint2 in /usr/local/lib/python3.7/dist-packages (from pyunpack) (1.0)\n",
            "Requirement already satisfied: patool in /usr/local/lib/python3.7/dist-packages (1.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec = load_word2vec(\"drive/MyDrive/Code_Frequencies_Embeddings/GoogleNews-vectors-negative300.bin\")"
      ],
      "metadata": {
        "id": "dpYJQNplvyKa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.embeddings import ELMoEmbeddings\n",
        "elmo = ELMoEmbeddings('original')"
      ],
      "metadata": {
        "id": "eHendhc5vyPq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Similarity Measure- Vector Average"
      ],
      "metadata": {
        "id": "gjacOREVbHQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(df, feature_names):\n",
        "    result = df.copy()\n",
        "    for feature_name in feature_names:\n",
        "        max_value = df[feature_name].max()\n",
        "        min_value = df[feature_name].min()\n",
        "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "aRiene-G9yDh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "def run_avg_benchmark(sentences1, sentences2, model=None, use_stoplist=False, doc_freqs=None):\n",
        "    if doc_freqs is not None:\n",
        "        N = doc_freqs[\"NUM_DOCS\"]\n",
        "\n",
        "    sims = []\n",
        "    for (sent1, sent2) in zip(sentences1, sentences2):\n",
        "\n",
        "        tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n",
        "        tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n",
        "\n",
        "        tokens1 = [token for token in tokens1 if token in model]\n",
        "        tokens2 = [token for token in tokens2 if token in model]\n",
        "\n",
        "        if len(tokens1) == 0 or len(tokens2) == 0:\n",
        "            sims.append(0)\n",
        "            continue\n",
        "\n",
        "        tokfreqs1 = Counter(tokens1)\n",
        "        tokfreqs2 = Counter(tokens2)\n",
        "\n",
        "        weights1 = [tokfreqs1[token] * math.log(N / (doc_freqs.get(token, 0) + 1))\n",
        "                    for token in tokfreqs1] if doc_freqs else None\n",
        "        weights2 = [tokfreqs2[token] * math.log(N / (doc_freqs.get(token, 0) + 1))\n",
        "                    for token in tokfreqs2] if doc_freqs else None\n",
        "\n",
        "        embedding1 = np.average([model[token] for token in tokfreqs1], axis=0, weights=weights1).reshape(1, -1)\n",
        "        embedding2 = np.average([model[token] for token in tokfreqs2], axis=0, weights=weights2).reshape(1, -1)\n",
        "\n",
        "        sim = cosine_similarity(embedding1, embedding2)[0][0]\n",
        "        sims.append(sim)\n",
        "\n",
        "    return sims\n"
      ],
      "metadata": {
        "id": "6TwaREJP-DUa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "STOP = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "class SentenceModel:\n",
        "\n",
        "    def __init__(self, sentence):\n",
        "        self.raw = sentence\n",
        "        #normalized_sentence = sentence.replace(\"'\", \"'\").replace(\"'\", \"'\")\n",
        "        self.tokens = [t.lower() for t in nltk.word_tokenize(sentence)]\n",
        "        self.tokens_without_stop = [t for t in self.tokens if t not in STOP]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3ZCrmF9-DYM",
        "outputId": "1945f5da-e134-4d90-bda4-e21975d46808"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(df, benchmark):\n",
        "    sentences1 = [SentenceModel(s) for s in df['question1']]\n",
        "    sentences2 = [SentenceModel(s) for s in df['question2']]\n",
        "\n",
        "    sims = benchmark[1](sentences1, sentences2)\n",
        "\n",
        "    return sims, benchmark[0]\n"
      ],
      "metadata": {
        "id": "9YbzE1Px-Db-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "from flair.data import Sentence\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def run_context_avg_benchmark(sentences1, sentences2, model=None, use_stoplist=False, doc_freqs=None):\n",
        "    if doc_freqs is not None:\n",
        "        N = doc_freqs[\"NUM_DOCS\"]\n",
        "\n",
        "    sims = []\n",
        "    for (sent1, sent2) in tqdm(zip(sentences1, sentences2), total=len(sentences1)):\n",
        "\n",
        "        tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n",
        "        tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n",
        "\n",
        "        flair_tokens1 = sent1.tokens\n",
        "        flair_tokens2 = sent2.tokens\n",
        "\n",
        "        flair_sent1 = Sentence(\" \".join(flair_tokens1))\n",
        "        flair_sent2 = Sentence(\" \".join(flair_tokens2))\n",
        "\n",
        "        model.embed(flair_sent1)\n",
        "        model.embed(flair_sent2)\n",
        "\n",
        "        embeddings_map1 = {}\n",
        "        embeddings_map2 = {}\n",
        "\n",
        "        for token in flair_sent1:\n",
        "            embeddings_map1[token.text] = np.array(token.embedding.data.tolist())\n",
        "\n",
        "        for token in flair_sent2:\n",
        "            embeddings_map2[token.text] = np.array(token.embedding.data.tolist())\n",
        "\n",
        "        if len(tokens1) == 0 or len(tokens2) == 0:\n",
        "            sims.append(0)\n",
        "            continue\n",
        "\n",
        "        tokfreqs1 = Counter(tokens1)\n",
        "        tokfreqs2 = Counter(tokens2)\n",
        "\n",
        "        weights1 = [tokfreqs1[token] * math.log(N / (doc_freqs.get(token, 0) + 1))\n",
        "                    for token in tokfreqs1 if token in embeddings_map1] if doc_freqs else None\n",
        "        weights2 = [tokfreqs2[token] * math.log(N / (doc_freqs.get(token, 0) + 1))\n",
        "                    for token in tokfreqs2 if token in embeddings_map2] if doc_freqs else None\n",
        "\n",
        "        embedding1 = np.average([embeddings_map1[token] for token in tokfreqs1 if token in embeddings_map1], axis=0, weights=weights1).reshape(1, -1)\n",
        "        embedding2 = np.average([embeddings_map2[token] for token in tokfreqs2 if token in embeddings_map2], axis=0, weights=weights2).reshape(1, -1)\n",
        "\n",
        "        sim = cosine_similarity(embedding1, embedding2)[0][0]\n",
        "        sims.append(sim)\n",
        "\n",
        "    return sims\n"
      ],
      "metadata": {
        "id": "iZhC6dcB-xjf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools as ft\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "benchmarks = [(\"AVG-W2V\", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=False)),\n",
        "              (\"AVG-ELMO\", ft.partial(run_context_avg_benchmark, model=elmo, use_stoplist=False)),\n",
        "              (\"AVG-W2V-STOP\", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=True)),\n",
        "              (\"AVG-ELMO-STOP\", ft.partial(run_context_avg_benchmark, model=elmo, use_stoplist=True)),\n",
        "              (\"AVG-W2V-TFIDF\", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=False, doc_freqs=doc_frequency)),\n",
        "              (\"AVG-ELMO-TFIDF\", ft.partial(run_context_avg_benchmark, model=elmo, use_stoplist=False, doc_freqs=doc_frequency)),\n",
        "              (\"AVG-W2V-TFIDF-STOP\",ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=True, doc_freqs=doc_frequency)),\n",
        "              (\"AVG-ELMO-TFIDF-STOP\",ft.partial(run_context_avg_benchmark, model=elmo, use_stoplist=True, doc_freqs=doc_frequency))]"
      ],
      "metadata": {
        "id": "LjJTfkhT7wGT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training=train.copy()"
      ],
      "metadata": {
        "id": "D3bftGMxae7y"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del training['id']\n",
        "del training['qid1']\n",
        "del training['qid2']"
      ],
      "metadata": {
        "id": "WqUx3ukKaap7"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "xcFG30UEV4Mo"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(25,20))\n",
        "row = 0\n",
        "column = 0\n",
        "training = normalize(training, [\"is_duplicate\"])\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for i in range(0, 8):\n",
        "    sims, topic = run_experiment(training, benchmarks[i])\n",
        "    pearson_correlation = scipy.stats.pearsonr(sims, training['is_duplicate'])[0]\n",
        "    spearman_correlation = scipy.stats.spearmanr(sims, training['is_duplicate'])[0]\n",
        "    rmse = sqrt(mean_squared_error(sims, training['is_duplicate']))\n",
        "    textstr = 'RMSE=%.3f\\n$Pearson Correlation=%.3f$\\n$Spearman Correlation=%.3f$'%(rmse, pearson_correlation, spearman_correlation)\n",
        "    training['predicted_sim'] = pd.Series(sims).values\n",
        "    training = training.sort_values('is_duplicate')\n",
        "    id = list(range(0, len(training.index)))\n",
        "    training['id'] = pd.Series(id).values\n",
        "    \n",
        "    if(i < 4):\n",
        "        row = 0\n",
        "        column = i\n",
        "    if(i >= 4 and i < 8):\n",
        "        row = 1\n",
        "        column = i-4\n",
        "\n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        \n",
        "    training.plot(kind='scatter', x='id', y='sim',color='DarkBlue', label='Similarity', title = topic, ax=axes[row, column]);\n",
        "    training.plot(kind='scatter', x='id', y='predicted_sim', color='DarkGreen', label='Predicted Similarity', ax=axes[row, column]);\n",
        "    axes[row, column].text(1500, 0, textstr, fontsize=12)\n",
        "    print (topic)\n",
        "    print (textstr)"
      ],
      "metadata": {
        "id": "wSPu_JMgtTo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Similarity Measure- Smooth Inverse Frequency"
      ],
      "metadata": {
        "id": "2RGn1vzsjfgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "def remove_first_principal_component(X):\n",
        "    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0)\n",
        "    print(X)\n",
        "    print(type(X))\n",
        "    svd.fit(X)\n",
        "    pc = svd.components_\n",
        "    XX = X - X.dot(pc.transpose()) * pc\n",
        "    return XX\n",
        "\n",
        "\n",
        "def run_sif_benchmark(sentences1, sentences2, model, freqs={}, use_stoplist=False, a=0.001):\n",
        "    total_freq = sum(freqs.values())\n",
        "\n",
        "    embeddings = []\n",
        "\n",
        "    # SIF requires us to first collect all sentence embeddings and then perform\n",
        "    # common component analysis.\n",
        "    for (sent1, sent2) in zip(sentences1, sentences2):\n",
        "        tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n",
        "        tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n",
        "\n",
        "        tokens1 = [token for token in tokens1 if token in model]\n",
        "        tokens2 = [token for token in tokens2 if token in model]\n",
        "\n",
        "        weights1 = [a / (a + freqs.get(token, 0) / total_freq) for token in tokens1]\n",
        "        weights2 = [a / (a + freqs.get(token, 0) / total_freq) for token in tokens2]\n",
        "\n",
        "        embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
        "        embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
        "\n",
        "        embeddings.append(embedding1)\n",
        "        embeddings.append(embedding2)\n",
        "\n",
        "    embeddings = remove_first_principal_component(np.array(embeddings))\n",
        "    sims = [cosine_similarity(embeddings[idx * 2].reshape(1, -1),\n",
        "                              embeddings[idx * 2 + 1].reshape(1, -1))[0][0]\n",
        "            for idx in range(int(len(embeddings) / 2))]\n",
        "\n",
        "    return sims\n"
      ],
      "metadata": {
        "id": "kPBEjKJxtcYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from flair.data import Sentence\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "def remove_first_principal_component(X):\n",
        "    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0)\n",
        "    svd.fit(X)\n",
        "    pc = svd.components_\n",
        "    XX = X - X.dot(pc.transpose()) * pc\n",
        "    return XX\n",
        "\n",
        "\n",
        "def run_context_sif_benchmark(sentences1, sentences2, model, freqs={}, use_stoplist=False, a=0.001):\n",
        "    total_freq = sum(freqs.values())\n",
        "\n",
        "    embeddings = []\n",
        "\n",
        "    # SIF requires us to first collect all sentence embeddings and then perform\n",
        "    # common component analysis.\n",
        "    for (sent1, sent2) in zip(sentences1, sentences2):\n",
        "        tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n",
        "        tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n",
        "\n",
        "        flair_tokens1 = sent1.tokens\n",
        "        flair_tokens2 = sent2.tokens\n",
        "\n",
        "        flair_sent1 = Sentence(\" \".join(flair_tokens1))\n",
        "        flair_sent2 = Sentence(\" \".join(flair_tokens2))\n",
        "\n",
        "        model.embed(flair_sent1)\n",
        "        model.embed(flair_sent2)\n",
        "\n",
        "        embeddings_map1 = {}\n",
        "        embeddings_map2 = {}\n",
        "\n",
        "        for token in flair_sent1:\n",
        "            embeddings_map1[token.text] = np.array(token.embedding.data.tolist())\n",
        "\n",
        "        for token in flair_sent2:\n",
        "            embeddings_map2[token.text] = np.array(token.embedding.data.tolist())\n",
        "\n",
        "        tokens1 = [token for token in tokens1]\n",
        "        tokens2 = [token for token in tokens2]\n",
        "\n",
        "        weights1 = [a / (a + freqs.get(token, 0) / total_freq) for token in tokens1]\n",
        "        weights2 = [a / (a + freqs.get(token, 0) / total_freq) for token in tokens2]\n",
        "\n",
        "        embedding1 = np.average([embeddings_map1[token] for token in tokens1], axis=0, weights=weights1)\n",
        "        embedding2 = np.average([embeddings_map2[token] for token in tokens2], axis=0, weights=weights2)\n",
        "\n",
        "        embeddings.append(embedding1)\n",
        "        embeddings.append(embedding2)\n",
        "\n",
        "    embeddings = remove_first_principal_component(np.array(embeddings))\n",
        "    sims = [cosine_similarity(embeddings[idx * 2].reshape(1, -1),\n",
        "                              embeddings[idx * 2 + 1].reshape(1, -1))[0][0]\n",
        "            for idx in range(int(len(embeddings) / 2))]\n",
        "\n",
        "    return sims\n"
      ],
      "metadata": {
        "id": "2FqfBj3TtcUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools as ft\n",
        "\n",
        "benchmarks = [(\"SIF-W2V\", ft.partial(run_sif_benchmark, freqs=frequency, model=word2vec, use_stoplist=False)),\n",
        "              (\"SIF-ELMO\", ft.partial(run_context_sif_benchmark, freqs=frequency, model=elmo, use_stoplist=False))]"
      ],
      "metadata": {
        "id": "g1OCpZW1tXye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(df, feature_names):\n",
        "    result = df.copy()\n",
        "    for feature_name in feature_names:\n",
        "        max_value = df[feature_name].max()\n",
        "        min_value = df[feature_name].min()\n",
        "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "zN6jUdyJtXwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "STOP = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "class SentenceModel:\n",
        "\n",
        "    def __init__(self, sentence):\n",
        "        self.raw = sentence\n",
        "        #normalized_sentence = sentence.replace(\"'\", \"'\").replace(\"'\", \"'\")\n",
        "        self.tokens = [t.lower() for t in nltk.word_tokenize(sentence)]\n",
        "        self.tokens_without_stop = [t for t in self.tokens if t not in STOP]"
      ],
      "metadata": {
        "id": "tmXEqDtxucxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(df, benchmark):\n",
        "    sentences1 = [SentenceModel(s) for s in df['question1']]\n",
        "    sentences2 = [SentenceModel(s) for s in df['question2']]\n",
        "\n",
        "    sims = benchmark[1](sentences1, sentences2)\n",
        "\n",
        "    return sims, benchmark[0]\n"
      ],
      "metadata": {
        "id": "76LuZ9G2ucmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,10))\n",
        "row = 0\n",
        "column = 0\n",
        "training = normalize(training, [\"is_duplicate\"])\n",
        "for i in range(0, 2):\n",
        "    sims, topic = run_experiment(training, benchmarks[i])\n",
        "    training['predicted_sim'] = pd.Series(sims).values\n",
        "    training = normalize(training, [\"predicted_sim\"])\n",
        "    pearson_correlation = scipy.stats.pearsonr(sims, training['sim'])[0]\n",
        "    spearman_correlation = scipy.stats.spearmanr(sims, training['sim'])[0]\n",
        "    rmse = sqrt(mean_squared_error(training['predicted_sim'], training['sim']))\n",
        "    textstr = 'rmse=%.3f\\n$Pearson Correlation=%.3f$\\n$Spearman Correlation=%.3f$'%(rmse, pearson_correlation, spearman_correlation)    \n",
        "    training = training.sort_values('sim')\n",
        "    id = list(range(0, len(training.index)))\n",
        "    training['id'] = pd.Series(id).values\n",
        "    \n",
        "    if(i < 2):\n",
        "        column = i\n",
        "        \n",
        "    training.plot(kind='scatter', x='id', y='sim',color='DarkBlue', label='Similarity', title = topic, ax=axes[column]);\n",
        "    training.plot(kind='scatter', x='id', y='predicted_sim', color='DarkGreen', label='Predicted Similarity', ax=axes[column]);\n",
        "    axes[column].text(1500, 0.05, textstr, fontsize=12)\n",
        "    print (topic)\n",
        "    print (textstr)"
      ],
      "metadata": {
        "id": "q0kOEcsMtXtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ab9SU7FTtXqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N1jG8XEAtXn4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}